"""
Google Gemini Live API í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì½”ë“œ (Vertex AI ë²„ì „)
google-genai SDKë¥¼ ì‚¬ìš©í•˜ì—¬ Vertex AIë¡œ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë° í…ìŠ¤íŠ¸ ëŒ€í™”ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import asyncio
import os
from google import genai
from google.genai import types

try:
    import pyaudio
    HAS_PYAUDIO = True
except ImportError:
    HAS_PYAUDIO = False


class GeminiLiveAPITestVertexAI:
    """Gemini Live API í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ (Vertex AI)"""
    
    def __init__(self, project_id: str, location: str = "us-central1", model_name: str = "gemini-live-2.5-flash-native-audio"):
        """
        Args:
            project_id: Google Cloud í”„ë¡œì íŠ¸ ID
            location: ë¦¬ì „ (ê¸°ë³¸ê°’: us-central1)
            model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: gemini-live-2.5-flash-native-audio)
        """
        print(f"ğŸ”§ Initializing client for Vertex AI...")
        print(f"   Project: {project_id}")
        print(f"   Location: {location}")
        
        self.client = genai.Client(
            vertexai=True,
            project=project_id,
            location=location
        )
        self.model_name = model_name
        self.session = None
        
        # ì˜¤ë””ì˜¤ ê´€ë ¨ ì´ˆê¸°í™”
        self.audio = None
        self.audio_stream = None
        self.audio_available = HAS_PYAUDIO
        
        if self.audio_available:
            try:
                self.audio = pyaudio.PyAudio()
                print("âœ… Audio system initialized.")
            except Exception as e:
                print(f"âš ï¸  Failed to initialize PyAudio: {e}")
                self.audio_available = False
        else:
            print("âš ï¸  PyAudio not found. Audio playback will be disabled.")
    
    def _setup_audio_stream(self):
        """ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì„¤ì •í•©ë‹ˆë‹¤ (24kHz, 16-bit PCM, Mono)."""
        if not self.audio_available or not self.audio:
            return
            
        try:
            print("ğŸ”ˆ Opening audio output stream (24kHz, 16-bit PCM, Mono)...")
            self.audio_stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=24000,
                output=True
            )
        except Exception as e:
            print(f"âŒ Failed to open audio stream: {e}")
            self.audio_available = False
    
    async def connect(self, initial_instruction: str = "You are a helpful assistant."):
        """
        Live API ì„¸ì…˜ ì—°ê²°ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        print(f"\nğŸ“¡ Connecting to Live API (Model: {self.model_name})")
        
        config = types.LiveConnectConfig(
            system_instruction=types.Content(
                parts=[types.Part(text=initial_instruction)]
            )
        )
        
        return self.client.aio.live.connect(
            model=self.model_name,
            config=config
        )
    
    async def handle_session_events(self):
        """ì„¸ì…˜ìœ¼ë¡œë¶€í„° ì‘ë‹µì„ ìˆ˜ì‹ í•˜ê³  ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        if not self.session:
            return
            
        print("\nğŸ‘‚ Listening for responses (Audio & Text)...")
        self._setup_audio_stream()
        
        try:
            async for response in self.session.receive():
                if response.server_content:
                    model_turn = response.server_content.model_turn
                    if model_turn:
                        for part in model_turn.parts:
                            # í…ìŠ¤íŠ¸ ì‘ë‹µ ì¶œë ¥
                            if part.text:
                                # ì–´ì‹œìŠ¤í„´íŠ¸ ì ‘ë‘ì–´ëŠ” í•œ ë²ˆë§Œ ì¶œë ¥ë˜ë„ë¡ ì²˜ë¦¬
                                print(f"{part.text}", end="", flush=True)
                            
                            # ì˜¤ë””ì˜¤ ë°ì´í„° ì¬ìƒ
                            if part.inline_data and self.audio_available and self.audio_stream:
                                try:
                                    self.audio_stream.write(part.inline_data.data)
                                except Exception as e:
                                    print(f"\nâŒ Audio playback error: {e}")
                                    self.audio_available = False
                    
                    if response.server_content.turn_complete:
                        print("\nâœ… Turn complete.")

                elif response.tool_call:
                    print(f"\nğŸ”§ Tool call: {response.tool_call}")
                    
        except asyncio.CancelledError:
            print("\nğŸ›‘ Listening task cancelled.")
        except Exception as e:
            print(f"\nâš ï¸  Session ended or error occurred: {e}")
        finally:
            self._close_audio_stream()

    def _close_audio_stream(self):
        """ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ë§Œ ë‹«ìŠµë‹ˆë‹¤."""
        if self.audio_stream:
            try:
                self.audio_stream.stop_stream()
                self.audio_stream.close()
            except:
                pass
            self.audio_stream = None
            print("\nğŸ”ˆ Audio stream closed.")

    def close(self):
        """ì „ì²´ ì˜¤ë””ì˜¤ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤."""
        self._close_audio_stream()
        if self.audio:
            try:
                self.audio.terminate()
            except:
                pass
            self.audio = None
    
    async def send_text(self, text: str, end_of_turn: bool = True):
        """í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡"""
        if not self.session:
            raise RuntimeError("Session not connected.")
        
        print(f"\nğŸ’¬ Sending user message: {text}")
        
        await self.session.send_client_content(
            turns=[
                types.Content(
                    role="user",
                    parts=[types.Part(text=text)]
                )
            ],
            turn_complete=end_of_turn
        )


async def run_scenario(tester, title, instruction, message):
    """ì§€ì •ëœ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒˆë¡œìš´ ì„¸ì…˜ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("\n" + "=" * 60)
    print(f"SCENARIO: {title}")
    # print(f"Instruction: {instruction[:50]}...")
    print("=" * 60)
    
    async with await tester.connect(initial_instruction=instruction) as session:
        tester.session = session
        listener = asyncio.create_task(tester.handle_session_events())
        
        await tester.send_text(message)
        
        # ì¶©ë¶„í•œ ì‘ë‹µ ì‹œê°„ì„ ìœ„í•´ ëŒ€ê¸° (ëª¨ë¸ì˜ ë§í•˜ê¸° ì†ë„ ê³ ë ¤)
        await asyncio.sleep(12)
        
        listener.cancel()
        await asyncio.gather(listener, return_exceptions=True)


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\nğŸš€ Google Gemini Live API í…ŒìŠ¤íŠ¸ ì‹œì‘ (Vertex AI)\n")
    project_id = "jwlee-argolis-202104"
    
    tester = GeminiLiveAPITestVertexAI(project_id=project_id)
    
    try:
        # ì‹œë‚˜ë¦¬ì˜¤ 1: ê¸°ë³¸ ëŒ€í™”
        await run_scenario(
            tester, 
            "1. Basic Conversation", 
            "You are a helpful assistant.", 
            "Hello! Who are you?"
        )
        
        # ì‹œë‚˜ë¦¬ì˜¤ 2: í˜ë¥´ì†Œë‚˜ ë³€ê²½ (í•´ì )
        await run_scenario(
            tester, 
            "2. Pirate Persona Update Test", 
            "You are now a pirate. Talk like one! Use 'Arrr' and 'Matey'.", 
            "What is your mission, captain?"
        )
        
        # ì‹œë‚˜ë¦¬ì˜¤ 3: í•œêµ­ì–´ ë¹„ì„œ
        await run_scenario(
            tester, 
            "3. Korean Assistant Locale Test", 
            "ë‹¹ì‹ ì€ ì´ì œ ì¹œì ˆí•œ í•œêµ­ì–´ ë¹„ì„œì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.", 
            "ì˜¤ëŠ˜ ë‚ ì”¨ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ì¤˜."
        )
        
    finally:
        tester.close()
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(main())
